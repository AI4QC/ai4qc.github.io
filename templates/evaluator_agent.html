{% set active_page = "Evaluator & Agent" %}
{% set page_title = "Evaluator & Agent" %}
{% extends "base.html" %}

{% block content %}
  <!-- Contact -->
 <title>Insert image left</title>
    <style>
      .image-wrapper {
      float: left;
      width: 45%;
      margin-left: 20px;
      margin-bottom: 10px;
    }

    .image-wrapper img {
      width: 100%;
      height: auto;
      display: block;
    }

    .text-content {
      overflow: hidden; /* ensures container grows around floated content */
    }
  </style>
</head>
<body>

  Evaluator & Agent are highly collaborative modules that  Collaboration with experiment teams
    {{ components.section("Evaluator : AI for Experimental Design") }}

<div class="text-content">
    <div class="image-wrapper">
      <img src="static/images/odbo.jpg" alt="ODBO figure">
    </div>
    <p>The goal of this direction is to transform the experimental design by <b> replacing trial-and-error with few-shot minimal data adaptive optimization</b> with approaches like <b> Bayesian optimization (BO)</b>, <b> active learning</b>, and <b> reinforcement learning</b> to efficient exploration of <b>complex and high-dimensional experimental spaces</b>. In our research, we build our models with <b>uncertainty-aware algorithm, outlier managements, low-dimensional representations, and domain-specific priors</b> to ensure practical performance in noisy and constrained real-world chemistry experimental settings. By forming <b> feedback loops</b>, we hope to help the experimentalists to provide a general tool to acheive closed-loop discovery in chemistry, biology, and materials science.</p>


    <p> <b> - <a href="https://arxiv.org/abs/2205.09548"> ODBO (Outlier-detected Bayesian Optimization)</a></b>: a ML protein directed evolution protocol that integrates low-dimensional and function-value-based protein encoding, search space prescreening with BO & outlier detection surrogate modeling to efficiently navigate noisy large sequence spaces and recommend high-fitness variants with minimal experimental cost.</p>


    {{ components.section("Problem-driven Fine-tuning and Benchmark Constructions for Scientific LLM Agent") }}

    In this topic, we plan to construct <b> domain-specific</b> datasets by combining outputs from upstream <b>simulation/emulation/prediction layers with curated data from literature data-mining</b>. We are also interested in collaborating with computer scientists to develop scientist-centric evaluation metrics for Scientific LLMs (e.g., NatureLM). This targeted approach ensures that fine-tuning aligns with real scientific tasks, enabling LLM agents to learn domain-relevant reasoning, symbolic logic, and experimental workflows grounded in chemistry. This direction will involve close collaboration with computer science groups to bridge foundation models and scientific discovery.






{% endblock %}
